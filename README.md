# SmartVisionQA: Real-Time Video Understanding & Query System

An AI-powered system that enables users to upload or stream video content and ask natural language questions about events happening within the video using state-of-the-art multimodal LLMs and computer vision.

## ğŸ¯ Real-World Use Cases

- **Security Teams**: Query surveillance footage for specific events without manual review
- **Teachers**: Review classroom recordings and identify key moments
- **Content Reviewers**: Quickly analyze video content at scale
- **Sports Analysts**: Find specific plays and events in game footage

## âœ¨ Advanced Features

- ğŸ¥ **Real-time Video Frame Processing**: Automatic chunking and CV model analysis
- ğŸ’¬ **Multimodal Q&A**: Ask questions like "Who entered the room after the teacher?"
- ğŸ” **Semantic Video Search**: Find moments like "3 people standing near the whiteboard"
- ğŸ“Š **Event Timeline Generation**: AI-powered summarization and clustering
- ğŸ”’ **Video Redaction**: Automatic face/object blurring
- ğŸ‘¥ **Collaborative Annotation**: Real-time collaborative mode with WebSocket

## ğŸ› ï¸ Tech Stack

### Frontend
- React with Vite
- Tailwind CSS
- WebRTC for streaming
- Socket.IO for real-time collaboration

### Backend
- FastAPI (Python)
- OpenCV for video processing
- YOLOv8 for object detection
- BLIP/LLaVA for vision-language reasoning
- Whisper for audio transcription
- ChromaDB for vector embeddings

### Infrastructure
- Docker & Docker Compose
- Redis for task queuing
- Local file storage (can extend to AWS S3)

## ğŸš€ Quick Start

### Prerequisites

- Python 3.9+
- Node.js 18+
- Git

### Installation

1. **Clone the repository**
```bash
git clone https://github.com/shreyaupretyy/smart-vision-qa.git
cd smart-vision-qa
```

2. **Set up backend**
```bash
# Create and activate virtual environment
python -m venv venv

# Windows
venv\Scripts\activate

# Linux/Mac
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

3. **Set up frontend**
```bash
cd frontend
npm install
cd ..
```

4. **Configure environment**
```bash
# Copy example env file
copy .env.example .env  # Windows
# or
cp .env.example .env    # Linux/Mac

# Edit .env with your settings
```

5. **Run with Docker (Recommended)**
```bash
docker-compose up --build
```

Or run manually:

```bash
# Terminal 1: Backend
venv\Scripts\activate  # Windows
uvicorn backend.main:app --reload --host 0.0.0.0 --port 8000

# Terminal 2: Frontend
cd frontend
npm run dev
```

6. **Access the application**
- Frontend: http://localhost:5173
- Backend API: http://localhost:8000
- API Docs: http://localhost:8000/docs

## ğŸ“ Project Structure

```
SmartVisionQA/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py                 # FastAPI application entry
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ routes.py          # API endpoints
â”‚   â”‚   â””â”€â”€ websocket.py       # WebSocket handlers
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ config.py          # Configuration
â”‚   â”‚   â””â”€â”€ dependencies.py    # Dependency injection
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ video_processor.py # Video processing
â”‚   â”‚   â”œâ”€â”€ object_detection.py# YOLOv8 integration
â”‚   â”‚   â”œâ”€â”€ vision_qa.py       # Vision-language QA
â”‚   â”‚   â”œâ”€â”€ transcription.py   # Whisper integration
â”‚   â”‚   â”œâ”€â”€ embeddings.py      # Vector embeddings
â”‚   â”‚   â”œâ”€â”€ timeline.py        # Event timeline
â”‚   â”‚   â””â”€â”€ redaction.py       # Video redaction
â”‚   â””â”€â”€ models/
â”‚       â””â”€â”€ schemas.py         # Pydantic models
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/        # React components
â”‚   â”‚   â”œâ”€â”€ pages/             # Page components
â”‚   â”‚   â”œâ”€â”€ services/          # API services
â”‚   â”‚   â””â”€â”€ utils/             # Utilities
â”‚   â”œâ”€â”€ public/
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ Dockerfile.backend
â”‚   â””â”€â”€ Dockerfile.frontend
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸ”§ API Endpoints

### Video Management
- `POST /api/video/upload` - Upload video file
- `GET /api/video/{video_id}` - Get video metadata
- `DELETE /api/video/{video_id}` - Delete video

### Analysis
- `POST /api/analyze/query` - Ask questions about video
- `POST /api/analyze/detect` - Run object detection
- `POST /api/analyze/transcribe` - Transcribe audio
- `GET /api/analyze/timeline/{video_id}` - Get event timeline
- `POST /api/analyze/search` - Semantic search in video

### Redaction
- `POST /api/redact/faces` - Blur faces in video
- `POST /api/redact/objects` - Blur specific objects

### Real-time
- `WebSocket /ws/stream` - Real-time video streaming
- `WebSocket /ws/collaborate` - Collaborative annotation

## ğŸ¨ Features in Detail

### 1. Video Upload & Processing
Upload videos in various formats (MP4, AVI, MOV, MKV). The system automatically extracts frames, generates embeddings, and prepares the video for analysis.

### 2. Multimodal Question Answering
Ask natural language questions about video content:
- "What objects are visible in the first 30 seconds?"
- "Who is wearing a red shirt?"
- "When did the person leave the room?"

### 3. Object Detection & Tracking
Real-time object detection using YOLOv8 with support for 80+ object classes. Track objects across frames for temporal analysis.

### 4. Semantic Search
Search for specific moments using natural language:
- "Find scenes with multiple people"
- "Show me when the door opens"
- "Locate moments with vehicles"

### 5. Event Timeline
Automatically generate a timeline of key events with AI-powered summarization and clustering of similar moments.

### 6. Video Redaction
Automatically detect and blur faces or specific objects for privacy protection. Export redacted videos with one click.

### 7. Collaborative Annotation
Multiple users can annotate videos in real-time with synchronized cursors and annotations.

## ğŸ§ª Development

### Running Tests
```bash
# Backend tests
pytest backend/tests/

# Frontend tests
cd frontend
npm test
```

### Code Quality
```bash
# Format code
black backend/
ruff check backend/

# Frontend linting
cd frontend
npm run lint
```

## ğŸ“ License

MIT License - see LICENSE file for details

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## ğŸ“§ Contact

For questions or support, please open an issue on GitHub.

## ğŸ™ Acknowledgments

- YOLOv8 by Ultralytics
- OpenAI Whisper
- Salesforce BLIP
- ChromaDB
- FastAPI
- React & Vite

---

Built with â¤ï¸ by the SmartVisionQA team
